{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W,name,padd,strid=[1,1,1,1]):\n",
    "    #El stride de esa función no reduce el tamaño de la imagen\n",
    "    return tf.nn.conv2d(x, W, strides=strid, padding=padd,name=name)\n",
    "\n",
    "def maxpool2d(x,ks,st):\n",
    "    #           El st de esta función reduce la imagen a la mitad\n",
    "    return tf.nn.max_pool(x, ksize=ks, strides=st, padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph():\n",
    "    #Limpiamos la gráfic\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deep_neural_convolutional_class(\n",
    "    batch_size=20,\n",
    "    image_size=[200,200],\n",
    "    Drop_prob=1.0,\n",
    "    learning_rate = 1e-2,\n",
    "    n_nodes_hl0 = 2000,\n",
    "    n_nodes_hl1 = 1000,\n",
    "    n_nodes_hl2 = 500,\n",
    "    n_nodes_hl3 = 100,\n",
    "    n_classes=8\n",
    "    ):\n",
    "    \n",
    "    reset_graph()\n",
    "    #Place holder de entrada \n",
    "    x= tf.placeholder(tf.float32,[batch_size,image_size[0],image_size[1],3], name='placeholder_img_entrada')\n",
    "    y=tf.placeholder('float',name='placeholder_one_hot')\n",
    "  \n",
    "    #Diccionario de pesos convolucionales \n",
    "    with tf.name_scope('pesos_bias') as scope1:\n",
    "        weigths={\"w_conv1\":tf.Variable(tf.random_normal([5,5,3,32]),name='Pesos_1_32'),\n",
    "                 \"w_conv2\":tf.Variable(tf.random_normal([5,5,32,64]),name='Pesos_1_64'),\n",
    "                 \"w_conv3\":tf.Variable(tf.random_normal([3,3,64,128]),name='Pesos_1_128'),   \n",
    "                 \"w_conv4\":tf.Variable(tf.random_normal([5,5,128,256]),name='Pesos_1_256'),\n",
    "                 \"w_conv5\":tf.Variable(tf.random_normal([5,5,256,512]),name='Pesos_1_512'),\n",
    "                 #\"w_conv6\":tf.Variable(tf.random_normal([5,5,512,1024]),name='Pesos_1_1024'),\n",
    "                }\n",
    "        #Diccionario de bias\n",
    "        biases={\"b_conv1\":tf.Variable(tf.random_normal([32]),name='Bias_1_32'),\n",
    "                \"b_conv2\":tf.Variable(tf.random_normal([64]),name='Bias_1_64'),\n",
    "                \"b_conv3\":tf.Variable(tf.random_normal([128]),name='Bias_1_128'),\n",
    "                \"b_conv4\":tf.Variable(tf.random_normal([256]),name='Bias_1_256'),\n",
    "                \"b_conv5\":tf.Variable(tf.random_normal([512]),name='Bias_1_512'),\n",
    "                #\"b_conv6\":tf.Variable(tf.random_normal([1024]),name='Bias_1_1024'),\n",
    "               }\n",
    "\n",
    "    #Extractor de características\n",
    "    with tf.name_scope('capas_conv') as scope2:\n",
    "        conv1=tf.nn.relu(conv2d(x,weigths[\"w_conv1\"],'Capa_Conv_1','SAME')+biases[\"b_conv1\"],name='Func_relu_1')\n",
    "        conv1=tf.nn.dropout(conv1,Drop_prob)\n",
    "        conv1=maxpool2d(conv1,ks=[1,2,2,1],st=[1,2,2,1])\n",
    "        #imagen resultante de 100x100x32\n",
    "        print(conv1)\n",
    "\n",
    "        conv2=tf.nn.relu(conv2d(conv1,weigths[\"w_conv2\"],'Capa_Conv_2','SAME')+biases[\"b_conv2\"],name='Func_relu_2')\n",
    "        conv2=tf.nn.dropout(conv2,Drop_prob)\n",
    "        conv2=maxpool2d(conv2,ks=[1,2,2,1],st=[1,2,2,1])\n",
    "        #imagen resultante de 50x50x64\n",
    "        print(conv2)\n",
    "\n",
    "        conv3=tf.nn.relu(conv2d(conv2,weigths[\"w_conv3\"],'Capa_Conv_3','VALID')+biases[\"b_conv3\"],name='Func_relu_3')\n",
    "        conv3=tf.nn.dropout(conv3,Drop_prob)\n",
    "        conv3=maxpool2d(conv3,ks=[1,2,2,1],st=[1,2,2,1])\n",
    "        #imagen resultante de 24x24x128\n",
    "        print(conv3)\n",
    "\n",
    "        conv4=tf.nn.relu(conv2d(conv3,weigths[\"w_conv4\"],'Capa_Conv_4','SAME')+biases[\"b_conv4\"],name='Func_relu_4')\n",
    "        conv4=tf.nn.dropout(conv4,Drop_prob)\n",
    "        conv4=maxpool2d(conv4,ks=[1,2,2,1],st=[1,2,2,1])\n",
    "        #imagen resultante de 12x12x256\n",
    "        print(conv4)\n",
    "\n",
    "        conv5=tf.nn.relu(conv2d(conv4, weigths[\"w_conv5\"],'Capa_Conv_5','SAME')+biases[\"b_conv5\"],name='Func_relu_5')\n",
    "        conv5=tf.nn.dropout(conv5,Drop_prob)\n",
    "        conv5=maxpool2d(conv5,ks=[1,2,2,1],st=[1,2,2,1])\n",
    "        #vector para clasificar de 6x6x512\n",
    "        print(conv5)\n",
    "        \n",
    "        #conv6=tf.nn.relu(conv2d(conv5, weigths[\"w_conv6\"],'Capa_Conv_6','SAME')+biases[\"b_conv6\"],name='Func_relu_6')\n",
    "        #conv6=tf.nn.dropout(conv6,Drop_prob)\n",
    "        #conv6=maxpool2d(conv6,ks=[1,4,4,1],st=[1,4,4,1])\n",
    "        #vector para clasificar de 1x1x1024\n",
    "        #print(conv6)\n",
    "\n",
    "        #Embeding, son las caracteristicas fonales que se pasarán al MLP o red completamente conectada para clasifiacar\n",
    "        embdeding=tf.reshape(conv5,[batch_size,6*6*512],name='Embeding')\n",
    "        print(embdeding)\n",
    "    \n",
    "    #Red perceptron, declaración de capas, son diccionarios de pesos y bias.\n",
    "    with tf.name_scope('capas_clasificador') as scope3:\n",
    "        hidden_0_layer = {'weights':tf.Variable(tf.random_normal([6*6*512, n_nodes_hl0]),name='Capa_oculta_pesos_0'),\n",
    "                          'biases':tf.Variable(tf.random_normal([n_nodes_hl0]),name='Capa_oculta_bias_0')}\n",
    "\n",
    "        hidden_1_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl0, n_nodes_hl1]),'Capa_oculta_pesos_1'),\n",
    "                          'biases':tf.Variable(tf.random_normal([n_nodes_hl1]),name='Capa_oculta_bias_1')}\n",
    "\n",
    "        hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2]),'Capa_oculta_pesos_2'),\n",
    "                          'biases':tf.Variable(tf.random_normal([n_nodes_hl2]),name='Capa_oculta_bias_2')}\n",
    "        \n",
    "        hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3]),'Capa_oculta_pesos_3'),\n",
    "                          'biases':tf.Variable(tf.random_normal([n_nodes_hl3]),name='Capa_oculta_bias_3')}\n",
    "\n",
    "        output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes]),'Capa_salida_pesos'),\n",
    "                        'biases':tf.Variable(tf.random_normal([n_classes]),name='Capa_salida_bias'),}\n",
    "    \n",
    "    #W*P + B \n",
    "    with tf.name_scope('op_clasificador') as scope4:\n",
    "        \n",
    "        l0 = tf.add(tf.matmul(embdeding,hidden_0_layer['weights'],name='Matmul_l0'), hidden_0_layer['biases'],name='Suma_Pesos_Bias_0')\n",
    "        l0 = tf.nn.relu(l0,name='l0_relu_0')\n",
    "\n",
    "        l1 = tf.add(tf.matmul(l0,hidden_1_layer['weights'],name='Matmul_l1'), hidden_1_layer['biases'],name='Suma_Pesos_Bias_1')\n",
    "        l1 = tf.nn.relu(l1,name='l1_relu_1')\n",
    "\n",
    "        l2 = tf.add(tf.matmul(l1,hidden_2_layer['weights'],name='Matmul_l2'), hidden_2_layer['biases'],name='Suma_Pesos_Bias_2')\n",
    "        l2 = tf.nn.relu(l2,name='l2_relu_2')\n",
    "        \n",
    "        l3 = tf.add(tf.matmul(l2,hidden_3_layer['weights'],name='Matmul_l3'), hidden_3_layer['biases'],name='Suma_Pesos_Bias_3')\n",
    "        l3 = tf.nn.relu(l3,name='l3_relu_3')\n",
    "\n",
    "        output = tf.matmul(l3,output_layer['weights'],name='Matmul_out') + output_layer['biases']\n",
    "    \n",
    "    # Declarando la funcion de costo y entrenamiento\n",
    "    #Reduce mean, reduce la dimencion del tensor en un promedio es decir hace el promedio del costo o error\n",
    "    with tf.name_scope('costo_y_optimizador') as scope5:\n",
    "        cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=y,name='cross_entropy_with_logits'),name='reduce_mean')\n",
    "        optimizer = tf.train.AdamOptimizer(name='Adam').minimize(cost,name='minimo')\n",
    "    \n",
    "    \n",
    "    tf.summary.scalar(\"costo\",cost)\n",
    "    correct = tf.equal(tf.argmax(output,1),tf.argmax(y,1),name='valores_correctos')\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,'float'),name='Promedio_exactitud') #porcentaje de error\n",
    "    tf.summary.scalar(\"accuracy\",accuracy)\n",
    "    summaries = tf.summary.merge_all()\n",
    "    \n",
    "    return dict(\n",
    "        x = x,\n",
    "        y=y,\n",
    "        embeding=conv5,\n",
    "        output=output,\n",
    "        saver = tf.train.Saver(),\n",
    "        total_loss = cost,\n",
    "        train_step = optimizer,\n",
    "        summaries = summaries,\n",
    "        accuracy = accuracy\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"capas_conv/MaxPool:0\", shape=(20, 100, 100, 32), dtype=float32)\n",
      "Tensor(\"capas_conv/MaxPool_1:0\", shape=(20, 50, 50, 64), dtype=float32)\n",
      "Tensor(\"capas_conv/MaxPool_2:0\", shape=(20, 24, 24, 128), dtype=float32)\n",
      "Tensor(\"capas_conv/MaxPool_3:0\", shape=(20, 12, 12, 256), dtype=float32)\n",
      "Tensor(\"capas_conv/MaxPool_4:0\", shape=(20, 6, 6, 512), dtype=float32)\n",
      "Tensor(\"capas_conv/Embeding:0\", shape=(20, 18432), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-4-be24a3093ed1>:115: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': <tf.Tensor 'Promedio_exactitud:0' shape=() dtype=float32>,\n",
       " 'embeding': <tf.Tensor 'capas_conv/MaxPool_4:0' shape=(20, 6, 6, 512) dtype=float32>,\n",
       " 'output': <tf.Tensor 'op_clasificador/add:0' shape=(20, 8) dtype=float32>,\n",
       " 'saver': <tensorflow.python.training.saver.Saver at 0x18154fb048>,\n",
       " 'summaries': <tf.Tensor 'Merge/MergeSummary:0' shape=() dtype=string>,\n",
       " 'total_loss': <tf.Tensor 'costo_y_optimizador/reduce_mean:0' shape=() dtype=float32>,\n",
       " 'train_step': <tf.Operation 'costo_y_optimizador/minimo' type=NoOp>,\n",
       " 'x': <tf.Tensor 'placeholder_img_entrada:0' shape=(20, 200, 200, 3) dtype=float32>,\n",
       " 'y': <tf.Tensor 'placeholder_one_hot:0' shape=<unknown> dtype=float32>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_neural_convolutional_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_img_encoder(G,nameBatch,numbatch, num_epochs,learning_rate = 1e-2, \n",
    "                      num_steps = 15, batch_size = 20, verbose = True, save=False,checkpoint=False):\n",
    "    tf.set_random_seed(2345)\n",
    "    print('Start training')\n",
    "    total_loss = 0\n",
    "    with tf.Session() as sess:\n",
    "        writer = tf.summary.FileWriter(\"./CNNClass\")\n",
    "        tf.summary.FileWriter.add_graph(writer,sess.graph)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        if checkpoint:\n",
    "            ENCname=\"./\"+checkpoint+\".ckpt\"\n",
    "            G['saver'].restore(sess, ENCname)\n",
    "        training_losses = []\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_loss = 0\n",
    "            for key in range(numbatch):\n",
    "                data=np.array(pickle.load(open(nameBatch+\".pickle\",\"rb\")))\n",
    "                dim,var=data.shape\n",
    "                for j in range(int(dim/batch_size)):\n",
    "                    epoch_x=data[batch_size*(j):batch_size*(j+1),0].tolist()\n",
    "                \n",
    "                    epoch_Y=data[batch_size*(j):batch_size*(j+1),1].tolist()\n",
    "\n",
    "                    feed_dict={G['x']: epoch_x,\n",
    "                               G['y']: epoch_Y,\n",
    "                              }\n",
    "                \n",
    "                    total_loss,_,summ = sess.run([G[\"total_loss\"],G[\"train_step\"],G[\"summaries\"]],feed_dict)\n",
    "                epoch_loss += total_loss\n",
    "                writer.add_summary(summ,epoch)\n",
    "            if verbose:\n",
    "                print(\"Average training loss for Epoch\", epoch, \":\", epoch_loss)\n",
    "            training_losses.append(epoch_loss)\n",
    "\n",
    "        if isinstance(save, str):\n",
    "            ENCname=\"./\"+save+\".ckpt\"\n",
    "            G['saver'].save(sess, ENCname)\n",
    "    return training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"capas_conv/MaxPool:0\", shape=(20, 100, 100, 32), dtype=float32)\n",
      "Tensor(\"capas_conv/MaxPool_1:0\", shape=(20, 50, 50, 64), dtype=float32)\n",
      "Tensor(\"capas_conv/MaxPool_2:0\", shape=(20, 24, 24, 128), dtype=float32)\n",
      "Tensor(\"capas_conv/MaxPool_3:0\", shape=(20, 12, 12, 256), dtype=float32)\n",
      "Tensor(\"capas_conv/MaxPool_4:0\", shape=(20, 6, 6, 512), dtype=float32)\n",
      "Tensor(\"capas_conv/Embeding:0\", shape=(20, 18432), dtype=float32)\n",
      "Start training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[131445435662336.0,\n",
       " 58170940588032.0,\n",
       " 32399920463872.0,\n",
       " 19591642218496.0,\n",
       " 19219538247680.0,\n",
       " 11517479092224.0,\n",
       " 10543045804032.0,\n",
       " 8368485826560.0,\n",
       " 7458580856832.0,\n",
       " 3649734443008.0,\n",
       " 5752747458560.0,\n",
       " 4220608315392.0,\n",
       " 11642659143680.0,\n",
       " 3647865094144.0,\n",
       " 1789712138240.0,\n",
       " 4576583352320.0,\n",
       " 1893643845632.0,\n",
       " 2423247077376.0,\n",
       " 2067958071296.0,\n",
       " 2755821830144.0,\n",
       " 4571733164032.0,\n",
       " 100356644864.0,\n",
       " 180230406144.0,\n",
       " 496874356736.0,\n",
       " 2138491584512.0,\n",
       " 1035171987456.0,\n",
       " 629186494464.0,\n",
       " 1159832010752.0,\n",
       " 654840561664.0,\n",
       " 136270020608.0,\n",
       " 1156162650112.0,\n",
       " 175916351488.0,\n",
       " 325473009664.0,\n",
       " 56848830464.0,\n",
       " 611034333184.0,\n",
       " 103840006144.0,\n",
       " 29676851200.0,\n",
       " 347722809344.0,\n",
       " 358273875968.0,\n",
       " 174220394496.0,\n",
       " 189075865600.0,\n",
       " 210221563904.0,\n",
       " 740865867776.0,\n",
       " 625640800256.0,\n",
       " 72005402624.0,\n",
       " 112172310528.0,\n",
       " 32825710592.0,\n",
       " 8953541632.0,\n",
       " 21000724480.0,\n",
       " 177889558528.0,\n",
       " 0.0,\n",
       " 46456938496.0,\n",
       " 76605685760.0,\n",
       " 167401422848.0,\n",
       " 112860119040.0,\n",
       " 23304163328.0,\n",
       " 30272878592.0,\n",
       " 58781433856.0,\n",
       " 50601164800.0,\n",
       " 80403881984.0,\n",
       " 83432603648.0,\n",
       " 307152191488.0,\n",
       " 24695144448.0,\n",
       " 27739226112.0,\n",
       " 51618709504.0,\n",
       " 44346580992.0,\n",
       " 95363932160.0,\n",
       " 28656361472.0,\n",
       " 0.0,\n",
       " 19403747328.0,\n",
       " 17842642944.0,\n",
       " 27536746496.0,\n",
       " 0.0,\n",
       " 24778534912.0,\n",
       " 54879039488.0,\n",
       " 25733791744.0,\n",
       " 44518850560.0,\n",
       " 558686601216.0,\n",
       " 0.0,\n",
       " 64695197696.0,\n",
       " 16036040704.0,\n",
       " 6484695552.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 50772463616.0,\n",
       " 0.0,\n",
       " 1459159040.0,\n",
       " 26782322688.0,\n",
       " 5900325888.0,\n",
       " 12865607680.0,\n",
       " 10171739136.0,\n",
       " 25219309568.0,\n",
       " 78370914304.0,\n",
       " 0.0,\n",
       " 5670345216.0,\n",
       " 2639126528.0,\n",
       " 27827648512.0,\n",
       " 7480495616.0,\n",
       " 0.0,\n",
       " 85379440640.0,\n",
       " 28161441792.0,\n",
       " 25907777536.0,\n",
       " 0.0,\n",
       " 10448304128.0,\n",
       " 14543001600.0,\n",
       " 1239246464.0,\n",
       " 46874931200.0,\n",
       " 11552456704.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 3647153920.0,\n",
       " 0.0,\n",
       " 68479696896.0,\n",
       " 5367237632.0,\n",
       " 0.0,\n",
       " 5228684288.0,\n",
       " 0.0,\n",
       " 1941851392.0,\n",
       " 30242617344.0,\n",
       " 0.0,\n",
       " 1474561664.0,\n",
       " 20420696064.0,\n",
       " 13308230656.0,\n",
       " 9403159552.0,\n",
       " 3426189312.0,\n",
       " 27935469568.0,\n",
       " 0.0,\n",
       " 6019268608.0,\n",
       " 2215639552.0,\n",
       " 2360983552.0,\n",
       " 0.0,\n",
       " 96966909952.0,\n",
       " 136278832.0,\n",
       " 1474160256.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 94001560.0,\n",
       " 0.0,\n",
       " 17973381120.0,\n",
       " 0.0,\n",
       " 413899168.0,\n",
       " 4791463424.0,\n",
       " 12097710080.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 763768064.0,\n",
       " 0.0,\n",
       " 12673132544.0,\n",
       " 10483807232.0,\n",
       " 1339193728.0,\n",
       " 0.0,\n",
       " 1993360256.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 3769688832.0,\n",
       " 3481048064.0,\n",
       " 1376126592.0,\n",
       " 3292072448.0,\n",
       " 711672640.0,\n",
       " 20035586048.0,\n",
       " 589463552.0,\n",
       " 1326833024.0,\n",
       " 0.0,\n",
       " 1010930496.0,\n",
       " 1913307136.0,\n",
       " 3800973312.0,\n",
       " 278218336.0,\n",
       " 18217027584.0,\n",
       " 3166927360.0,\n",
       " 0.0,\n",
       " 855504512.0,\n",
       " 4501255168.0,\n",
       " 1771642880.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 590101696.0,\n",
       " 22547562496.0,\n",
       " 3772596992.0,\n",
       " 91871640.0,\n",
       " 605373248.0,\n",
       " 6151340544.0,\n",
       " 3713762816.0,\n",
       " 0.0,\n",
       " 66784872.0,\n",
       " 11264001024.0,\n",
       " 1665587584.0,\n",
       " 166879346688.0,\n",
       " 0.0,\n",
       " 438454528.0,\n",
       " 6137443328.0,\n",
       " 2743931904.0,\n",
       " 1207500.875,\n",
       " 0.0,\n",
       " 6486971392.0,\n",
       " 0.0,\n",
       " 768136832.0,\n",
       " 1450057728.0,\n",
       " 0.0,\n",
       " 2967123712.0,\n",
       " 626422784.0,\n",
       " 1119846.375,\n",
       " 5063000576.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 6537841664.0,\n",
       " 2091705984.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 12540667904.0,\n",
       " 0.0,\n",
       " 719553344.0,\n",
       " 2415944192.0,\n",
       " 383732960.0,\n",
       " 607551872.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 462597344.0,\n",
       " 0.0,\n",
       " 12811633664.0,\n",
       " 811098944.0,\n",
       " 937574.4375,\n",
       " 3262859008.0,\n",
       " 6128228864.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 7555773440.0,\n",
       " 5762917888.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 6969378304.0,\n",
       " 982250432.0,\n",
       " 1796210304.0,\n",
       " 0.0,\n",
       " 340755872.0,\n",
       " 111040128.0,\n",
       " 897105920.0,\n",
       " 4132981760.0,\n",
       " 0.0,\n",
       " 615434688.0,\n",
       " 837055488.0,\n",
       " 0.0,\n",
       " 1691580672.0,\n",
       " 489183136.0,\n",
       " 641745344.0,\n",
       " 105262288.0,\n",
       " 145997616.0,\n",
       " 0.0,\n",
       " 841903552.0,\n",
       " 0.0,\n",
       " 81082040.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 2336962560.0,\n",
       " 696070144.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1236741376.0,\n",
       " 1809875968.0,\n",
       " 432170560.0,\n",
       " 0.0,\n",
       " 557746816.0,\n",
       " 0.0,\n",
       " 265404832.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 218052608.0,\n",
       " 971015296.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4367713792.0,\n",
       " 0.0,\n",
       " 192953344.0,\n",
       " 771432448.0,\n",
       " 0.0,\n",
       " 63297640.0,\n",
       " 122522832.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4343070720.0,\n",
       " 0.0,\n",
       " 4287590400.0,\n",
       " 1504189312.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 12718949376.0,\n",
       " 1115129600.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 167348528.0,\n",
       " 0.0,\n",
       " 1783794944.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/home/sia/Escritorio/AreasVerdesTraining/CT30mSupFinal' \n",
    "encoder=deep_neural_convolutional_class(batch_size = 20)\n",
    "train_img_encoder(encoder,path,1, 300,save=\"AreaVerde30m\",batch_size = 20,verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9101, 2)\n"
     ]
    }
   ],
   "source": [
    "arr = np.array(pickle.load(open('/home/sia/Escritorio/AreasVerdesTraining/CT30mSupFinal.pickle','rb')))\n",
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_net(g, test, checkpoint):\n",
    "    \"\"\" Accepts a current character, initial state\"\"\"\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        writer = tf.summary.FileWriter(\"./CNNClass\")\n",
    "        tf.summary.FileWriter.add_graph(writer,sess.graph)\n",
    "        #sess.run(tf.initialize_all_variables())\n",
    "        g['saver'].restore(sess, checkpoint)\n",
    "        \n",
    "        feed_dict={g['x']: test[:,0].tolist(),g['y']: test[:,1].tolist()}\n",
    "        preds,accuracy = sess.run([g['output'],g['accuracy']], feed_dict)\n",
    "    return preds,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(824, 2)\n",
      "Tensor(\"capas_conv/MaxPool:0\", shape=(824, 100, 100, 32), dtype=float32)\n",
      "Tensor(\"capas_conv/MaxPool_1:0\", shape=(824, 50, 50, 64), dtype=float32)\n",
      "Tensor(\"capas_conv/MaxPool_2:0\", shape=(824, 24, 24, 128), dtype=float32)\n",
      "Tensor(\"capas_conv/MaxPool_3:0\", shape=(824, 12, 12, 256), dtype=float32)\n",
      "Tensor(\"capas_conv/MaxPool_4:0\", shape=(824, 6, 6, 512), dtype=float32)\n",
      "Tensor(\"capas_conv/Embeding:0\", shape=(824, 18432), dtype=float32)\n",
      "INFO:tensorflow:Restoring parameters from ./AreaVerde30m.ckpt\n"
     ]
    }
   ],
   "source": [
    "path= '/home/sia/Escritorio/AreasVerdesTraining/CT30mPruFinal'\n",
    "data1=np.array(pickle.load(open(path+\".pickle\",\"rb\"))) #np.load()\n",
    "print(data1.shape)\n",
    "g=deep_neural_convolutional_class(batch_size = 824)\n",
    "pred,accuracy=check_net(g,data1, \"./AreaVerde30m.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.723301\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deep_neural_convolutional_class_check(\n",
    "    batch_size=20,\n",
    "    image_size=[200,200],\n",
    "    Drop_prob=1.0,\n",
    "    learning_rate = 1e-2,\n",
    "    n_nodes_hl0 = 2000,\n",
    "    n_nodes_hl1 = 1000,\n",
    "    n_nodes_hl2 = 500,\n",
    "    n_nodes_hl3 = 100,\n",
    "    n_classes=8\n",
    "    ):\n",
    "    \n",
    "    reset_graph()\n",
    "    #Place holder de entrada \n",
    "    x= tf.placeholder(tf.float32,[batch_size,image_size[0],image_size[1],3], name='placeholder_img_entrada')\n",
    "    y=tf.placeholder('float',name='placeholder_one_hot')\n",
    "  \n",
    "    #Diccionario de pesos convolucionales \n",
    "    with tf.name_scope('pesos_bias') as scope1:\n",
    "        weigths={\"w_conv1\":tf.Variable(tf.random_normal([5,5,3,32]),name='Pesos_1_32'),\n",
    "                 \"w_conv2\":tf.Variable(tf.random_normal([5,5,32,64]),name='Pesos_1_64'),\n",
    "                 \"w_conv3\":tf.Variable(tf.random_normal([3,3,64,128]),name='Pesos_1_128'),   \n",
    "                 \"w_conv4\":tf.Variable(tf.random_normal([5,5,128,256]),name='Pesos_1_256'),\n",
    "                 \"w_conv5\":tf.Variable(tf.random_normal([5,5,256,512]),name='Pesos_1_512'),\n",
    "                 #\"w_conv6\":tf.Variable(tf.random_normal([5,5,512,1024]),name='Pesos_1_1024'),\n",
    "                }\n",
    "        #Diccionario de bias\n",
    "        biases={\"b_conv1\":tf.Variable(tf.random_normal([32]),name='Bias_1_32'),\n",
    "                \"b_conv2\":tf.Variable(tf.random_normal([64]),name='Bias_1_64'),\n",
    "                \"b_conv3\":tf.Variable(tf.random_normal([128]),name='Bias_1_128'),\n",
    "                \"b_conv4\":tf.Variable(tf.random_normal([256]),name='Bias_1_256'),\n",
    "                \"b_conv5\":tf.Variable(tf.random_normal([512]),name='Bias_1_512'),\n",
    "                #\"b_conv6\":tf.Variable(tf.random_normal([1024]),name='Bias_1_1024'),\n",
    "               }\n",
    "\n",
    "    #Extractor de características\n",
    "    with tf.name_scope('capas_conv') as scope2:\n",
    "        conv1=tf.nn.relu(conv2d(x,weigths[\"w_conv1\"],'Capa_Conv_1','SAME')+biases[\"b_conv1\"],name='Func_relu_1')\n",
    "        conv1=tf.nn.dropout(conv1,Drop_prob)\n",
    "        conv1=maxpool2d(conv1,ks=[1,2,2,1],st=[1,2,2,1])\n",
    "        #imagen resultante de 100x100x32\n",
    "        print(conv1)\n",
    "\n",
    "        conv2=tf.nn.relu(conv2d(conv1,weigths[\"w_conv2\"],'Capa_Conv_2','SAME')+biases[\"b_conv2\"],name='Func_relu_2')\n",
    "        conv2=tf.nn.dropout(conv2,Drop_prob)\n",
    "        conv2=maxpool2d(conv2,ks=[1,2,2,1],st=[1,2,2,1])\n",
    "        #imagen resultante de 50x50x64\n",
    "        print(conv2)\n",
    "\n",
    "        conv3=tf.nn.relu(conv2d(conv2,weigths[\"w_conv3\"],'Capa_Conv_3','VALID')+biases[\"b_conv3\"],name='Func_relu_3')\n",
    "        conv3=tf.nn.dropout(conv3,Drop_prob)\n",
    "        conv3=maxpool2d(conv3,ks=[1,2,2,1],st=[1,2,2,1])\n",
    "        #imagen resultante de 24x24x128\n",
    "        print(conv3)\n",
    "\n",
    "        conv4=tf.nn.relu(conv2d(conv3,weigths[\"w_conv4\"],'Capa_Conv_4','SAME')+biases[\"b_conv4\"],name='Func_relu_4')\n",
    "        conv4=tf.nn.dropout(conv4,Drop_prob)\n",
    "        conv4=maxpool2d(conv4,ks=[1,2,2,1],st=[1,2,2,1])\n",
    "        #imagen resultante de 12x12x256\n",
    "        print(conv4)\n",
    "\n",
    "        conv5=tf.nn.relu(conv2d(conv4, weigths[\"w_conv5\"],'Capa_Conv_5','SAME')+biases[\"b_conv5\"],name='Func_relu_5')\n",
    "        conv5=tf.nn.dropout(conv5,Drop_prob)\n",
    "        conv5=maxpool2d(conv5,ks=[1,2,2,1],st=[1,2,2,1])\n",
    "        #vector para clasificar de 6x6x512\n",
    "        print(conv5)\n",
    "        \n",
    "        #conv6=tf.nn.relu(conv2d(conv5, weigths[\"w_conv6\"],'Capa_Conv_6','SAME')+biases[\"b_conv6\"],name='Func_relu_6')\n",
    "        #conv6=tf.nn.dropout(conv6,Drop_prob)\n",
    "        #conv6=maxpool2d(conv6,ks=[1,4,4,1],st=[1,4,4,1])\n",
    "        #vector para clasificar de 1x1x1024\n",
    "        #print(conv6)\n",
    "\n",
    "        #Embeding, son las caracteristicas fonales que se pasarán al MLP o red completamente conectada para clasifiacar\n",
    "        embdeding=tf.reshape(conv5,[batch_size,6*6*512],name='Embeding')\n",
    "        print(embdeding)\n",
    "    \n",
    "    #Red perceptron, declaración de capas, son diccionarios de pesos y bias.\n",
    "    with tf.name_scope('capas_clasificador') as scope3:\n",
    "        hidden_0_layer = {'weights':tf.Variable(tf.random_normal([6*6*512, n_nodes_hl0]),name='Capa_oculta_pesos_0'),\n",
    "                          'biases':tf.Variable(tf.random_normal([n_nodes_hl0]),name='Capa_oculta_bias_0')}\n",
    "\n",
    "        hidden_1_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl0, n_nodes_hl1]),'Capa_oculta_pesos_1'),\n",
    "                          'biases':tf.Variable(tf.random_normal([n_nodes_hl1]),name='Capa_oculta_bias_1')}\n",
    "\n",
    "        hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2]),'Capa_oculta_pesos_2'),\n",
    "                          'biases':tf.Variable(tf.random_normal([n_nodes_hl2]),name='Capa_oculta_bias_2')}\n",
    "        \n",
    "        hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3]),'Capa_oculta_pesos_3'),\n",
    "                          'biases':tf.Variable(tf.random_normal([n_nodes_hl3]),name='Capa_oculta_bias_3')}\n",
    "\n",
    "        output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes]),'Capa_salida_pesos'),\n",
    "                        'biases':tf.Variable(tf.random_normal([n_classes]),name='Capa_salida_bias'),}\n",
    "    \n",
    "    #W*P + B \n",
    "    with tf.name_scope('op_clasificador') as scope4:\n",
    "        \n",
    "        l0 = tf.add(tf.matmul(embdeding,hidden_0_layer['weights'],name='Matmul_l0'), hidden_0_layer['biases'],name='Suma_Pesos_Bias_0')\n",
    "        l0 = tf.nn.relu(l0,name='l0_relu_0')\n",
    "\n",
    "        l1 = tf.add(tf.matmul(l0,hidden_1_layer['weights'],name='Matmul_l1'), hidden_1_layer['biases'],name='Suma_Pesos_Bias_1')\n",
    "        l1 = tf.nn.relu(l1,name='l1_relu_1')\n",
    "\n",
    "        l2 = tf.add(tf.matmul(l1,hidden_2_layer['weights'],name='Matmul_l2'), hidden_2_layer['biases'],name='Suma_Pesos_Bias_2')\n",
    "        l2 = tf.nn.relu(l2,name='l2_relu_2')\n",
    "        \n",
    "        l3 = tf.add(tf.matmul(l2,hidden_3_layer['weights'],name='Matmul_l3'), hidden_3_layer['biases'],name='Suma_Pesos_Bias_3')\n",
    "        l3 = tf.nn.relu(l3,name='l3_relu_3')\n",
    "\n",
    "        output = tf.matmul(l3,output_layer['weights'],name='Matmul_out') + output_layer['biases']\n",
    "        output1 = tf.argmax(output,1)\n",
    "        \n",
    "    return dict(\n",
    "        x = x,\n",
    "        embeding=conv5,\n",
    "        output=output1,\n",
    "        saver = tf.train.Saver(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"capas_conv/MaxPool:0\", shape=(20, 100, 100, 32), dtype=float32)\n",
      "Tensor(\"capas_conv/MaxPool_1:0\", shape=(20, 50, 50, 64), dtype=float32)\n",
      "Tensor(\"capas_conv/MaxPool_2:0\", shape=(20, 24, 24, 128), dtype=float32)\n",
      "Tensor(\"capas_conv/MaxPool_3:0\", shape=(20, 12, 12, 256), dtype=float32)\n",
      "Tensor(\"capas_conv/MaxPool_4:0\", shape=(20, 6, 6, 512), dtype=float32)\n",
      "Tensor(\"capas_conv/Embeding:0\", shape=(20, 18432), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'embeding': <tf.Tensor 'capas_conv/MaxPool_4:0' shape=(20, 6, 6, 512) dtype=float32>,\n",
       " 'output': <tf.Tensor 'op_clasificador/ArgMax:0' shape=(20,) dtype=int64>,\n",
       " 'saver': <tensorflow.python.training.saver.Saver at 0x1815b18940>,\n",
       " 'x': <tf.Tensor 'placeholder_img_entrada:0' shape=(20, 200, 200, 3) dtype=float32>}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_neural_convolutional_class_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_net(g, test, checkpoint):\n",
    "    \"\"\" Accepts a current character, initial state\"\"\"\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        writer = tf.summary.FileWriter(\"./CNNClass\")\n",
    "        tf.summary.FileWriter.add_graph(writer,sess.graph)\n",
    "        #sess.run(tf.initialize_all_variables())\n",
    "        g['saver'].restore(sess, checkpoint)\n",
    "        \n",
    "        feed_dict={g['x']: test[:,0].tolist()}\n",
    "        preds = sess.run(g['output'], feed_dict)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "824\n",
      "Tensor(\"capas_conv/MaxPool:0\", shape=(824, 100, 100, 32), dtype=float32)\n",
      "Tensor(\"capas_conv/MaxPool_1:0\", shape=(824, 50, 50, 64), dtype=float32)\n",
      "Tensor(\"capas_conv/MaxPool_2:0\", shape=(824, 24, 24, 128), dtype=float32)\n",
      "Tensor(\"capas_conv/MaxPool_3:0\", shape=(824, 12, 12, 256), dtype=float32)\n",
      "Tensor(\"capas_conv/MaxPool_4:0\", shape=(824, 6, 6, 512), dtype=float32)\n",
      "Tensor(\"capas_conv/Embeding:0\", shape=(824, 18432), dtype=float32)\n",
      "INFO:tensorflow:Restoring parameters from /Users/anayantzinp/Desktop/TT-II/AreasVerdesTraining_v2/AreaVerde30m.ckpt\n"
     ]
    }
   ],
   "source": [
    "path='/Users/anayantzinp/Desktop/TT-II/Conjunto_Entrenamiento/CE200/Pepinillos/CT30mPruFinal'\n",
    "data1=np.array(pickle.load(open(path+\".pickle\",\"rb\"))) #np.load()\n",
    "print(len(data1))\n",
    "g=deep_neural_convolutional_class(batch_size = len(data1))\n",
    "pred=check_net(g,data1, '/Users/anayantzinp/Desktop/TT-II/AreasVerdesTraining_v2/AreaVerde30m.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.49141062e+11  2.07372616e+11  2.46408872e+11 ...  4.10475725e+09\n",
      "   2.25942831e+11  2.44398539e+11]\n",
      " [ 4.85564056e+11  2.50098057e+11  1.87332542e+11 ...  9.56431892e+10\n",
      "  -2.82470154e+11  1.31784428e+10]\n",
      " [ 1.37282871e+11  1.52139989e+11  6.91871744e+10 ...  8.39089848e+10\n",
      "   5.69694290e+10  5.45018225e+10]\n",
      " ...\n",
      " [ 7.69681572e+10  7.15962614e+10  4.11004969e+10 ...  2.60257587e+10\n",
      "   4.03881411e+10  1.58265989e+10]\n",
      " [ 1.91462982e+11  1.62182250e+11  1.07549114e+11 ...  5.71565793e+10\n",
      "   2.46513631e+11  5.10415340e+10]\n",
      " [-3.30493051e+10 -2.88611840e+10 -1.71080417e+10 ... -2.46396396e+10\n",
      "  -3.71821486e+10 -4.96908247e+10]]\n"
     ]
    }
   ],
   "source": [
    "pred2 = pred\n",
    "print(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258574060000.0\n",
      "485564060000.0\n",
      "243617020000.0\n",
      "39710994000.0\n",
      "7587444700.0\n",
      "1144352700000.0\n",
      "1159550200000.0\n",
      "406482320000.0\n",
      "23580387000.0\n",
      "435618870000.0\n",
      "376521230000.0\n",
      "2824778300000.0\n",
      "-5299089400.0\n",
      "-15700054000.0\n",
      "44819610000.0\n",
      "268263780000.0\n",
      "80407950000.0\n",
      "23885066000.0\n",
      "444238230000.0\n",
      "328603700000.0\n",
      "217870140000.0\n",
      "109996280000.0\n",
      "33499963000.0\n",
      "880954500000.0\n",
      "179938720000.0\n",
      "129388175000.0\n",
      "1018589940000.0\n",
      "4782850000.0\n",
      "572152150000.0\n",
      "251477620000.0\n",
      "120662640000.0\n",
      "61783940000.0\n",
      "42440450000.0\n",
      "284822270000.0\n",
      "58652220000.0\n",
      "48046817000.0\n",
      "2373876400000.0\n",
      "-10408660000.0\n",
      "435308700000.0\n",
      "153907580000.0\n",
      "31673358000.0\n",
      "-16466760000.0\n",
      "81365385000.0\n",
      "71645420000.0\n",
      "28701684000.0\n",
      "327281340000.0\n",
      "1641190500000.0\n",
      "1396919800000.0\n",
      "-7344568300.0\n",
      "32055734000.0\n",
      "1422138400000.0\n",
      "731590700000.0\n",
      "253105200000.0\n",
      "203875000000.0\n",
      "111755360000.0\n",
      "134477470000.0\n",
      "99722895000.0\n",
      "227977300000.0\n",
      "520602980000.0\n",
      "12483887000.0\n",
      "176137470000.0\n",
      "19154174000.0\n",
      "-54411575000.0\n",
      "120506610000.0\n",
      "104156710000.0\n",
      "276723240000.0\n",
      "-2461659100.0\n",
      "131486860000.0\n",
      "-19893617000.0\n",
      "-33741595000.0\n",
      "167176950000.0\n",
      "29753178000.0\n",
      "27710185000.0\n",
      "21610439000.0\n",
      "1229440300000.0\n",
      "1535489200000.0\n",
      "214830190000.0\n",
      "329565200000.0\n",
      "911608500000.0\n",
      "155175160000.0\n",
      "457507470000.0\n",
      "164639930000.0\n",
      "202815700000.0\n",
      "-18317353000.0\n",
      "85659750000.0\n",
      "107485050000.0\n",
      "2668141200000.0\n",
      "284028340000.0\n",
      "-67578960000.0\n",
      "132859000000.0\n",
      "-32331583000.0\n",
      "122899350000.0\n",
      "693783000000.0\n",
      "38946783000.0\n",
      "443664600000.0\n",
      "1435665400.0\n",
      "138591010000.0\n",
      "29658650000.0\n",
      "19728470000.0\n",
      "35030060000.0\n",
      "461766520000.0\n",
      "26574266000.0\n",
      "567811700000.0\n",
      "-172570790000.0\n",
      "469699000000.0\n",
      "-42245260000.0\n",
      "282811170000.0\n",
      "173750350000.0\n",
      "7428462600.0\n",
      "284009140000.0\n",
      "52446460000.0\n",
      "891079560000.0\n",
      "-1860990000.0\n",
      "49133240000.0\n",
      "191101440000.0\n",
      "67484230000.0\n",
      "1494823900000.0\n",
      "870795600000.0\n",
      "476380270000.0\n",
      "194557330000.0\n",
      "96710296000.0\n",
      "521034830000.0\n",
      "94634040000.0\n",
      "8726871000000.0\n",
      "255411490000.0\n",
      "101308604000.0\n",
      "-72885010000.0\n",
      "-2656012300.0\n",
      "330602840000.0\n",
      "329367800000.0\n",
      "334208000000.0\n",
      "495239760000.0\n",
      "321416720000.0\n",
      "198878330000.0\n",
      "-26643833000.0\n",
      "809178560000.0\n",
      "-30511968000.0\n",
      "458810520000.0\n",
      "-26968908000.0\n",
      "3274030400000.0\n",
      "96939720000.0\n",
      "-25498028000.0\n",
      "115405580000.0\n",
      "832674700000.0\n",
      "667630400000.0\n",
      "79473740000.0\n",
      "262721180000.0\n",
      "293222020000.0\n",
      "451166440000.0\n",
      "208433270000.0\n",
      "452735830000.0\n",
      "-9296820000.0\n",
      "69235600000.0\n",
      "-24762544000.0\n",
      "244609480000.0\n",
      "23274836000.0\n",
      "797940500000.0\n",
      "16049797000.0\n",
      "139526140000.0\n",
      "139872450000.0\n",
      "23212380000.0\n",
      "17456202000.0\n",
      "147250920000.0\n",
      "-11862589000.0\n",
      "-21798334000.0\n",
      "14149535000.0\n",
      "6711574500.0\n",
      "1947141700000.0\n",
      "275138580000.0\n",
      "16431819000.0\n",
      "18071388000.0\n",
      "173224260000.0\n",
      "17994076000.0\n",
      "32778910000.0\n",
      "148804390000.0\n",
      "-6539712500.0\n",
      "483527520000.0\n",
      "-38433920000.0\n",
      "557206700000.0\n",
      "-15405756000.0\n",
      "188465350000.0\n",
      "103900600000.0\n",
      "219406880000.0\n",
      "633731740000.0\n",
      "549784800000.0\n",
      "17587143000.0\n",
      "404198400000.0\n",
      "-40165790000.0\n",
      "367560500000.0\n",
      "12988121000.0\n",
      "4532576000000.0\n",
      "223647000000.0\n",
      "14885699000.0\n",
      "23688077000.0\n",
      "24549296000.0\n",
      "187985580000.0\n",
      "-60110873000.0\n",
      "895903600000.0\n",
      "24158126000.0\n",
      "112988440000.0\n",
      "-219858430.0\n",
      "142360630000.0\n",
      "2757083100.0\n",
      "230413760000.0\n",
      "-10906350000.0\n",
      "174886030000.0\n",
      "465107450000.0\n",
      "54754062000.0\n",
      "81760580000.0\n",
      "1416317000000.0\n",
      "511191300000.0\n",
      "276433600000.0\n",
      "658667500000.0\n",
      "843563700000.0\n",
      "29274853000.0\n",
      "121214860000.0\n",
      "430315730000.0\n",
      "234846930000.0\n",
      "642401900000.0\n",
      "604861800000.0\n",
      "48262152000.0\n",
      "23383245000.0\n",
      "127026300000.0\n",
      "84908605000.0\n",
      "438187260000.0\n",
      "779092300000.0\n",
      "197879530000.0\n",
      "57433387000.0\n",
      "20546916000.0\n",
      "283064830000.0\n",
      "-26823231000.0\n",
      "562898100000.0\n",
      "21017915000.0\n",
      "11941020000.0\n",
      "57093177000.0\n",
      "-10997199000.0\n",
      "341351200000.0\n",
      "-39768973000.0\n",
      "9070989000.0\n",
      "301593200000.0\n",
      "58326446000.0\n",
      "76211690000.0\n",
      "81868120000.0\n",
      "-8128143400.0\n",
      "23877538000.0\n",
      "11738573000.0\n",
      "1223149000000.0\n",
      "-24351367000.0\n",
      "-60275565000.0\n",
      "129158830000.0\n",
      "3185824800.0\n",
      "412357660000.0\n",
      "189790810000.0\n",
      "50544574000.0\n",
      "22327489000.0\n",
      "19062936000.0\n",
      "12411183000.0\n",
      "813851600000.0\n",
      "2416952300.0\n",
      "2589074400.0\n",
      "-17627767000.0\n",
      "1089822200000.0\n",
      "84415610000.0\n",
      "-4130734800.0\n",
      "200114270000.0\n",
      "-8997474000.0\n",
      "22553100000.0\n",
      "-27859673000.0\n",
      "283490030000.0\n",
      "59275650000.0\n",
      "8733311000.0\n",
      "289203220000.0\n",
      "1334837200000.0\n",
      "34007820000.0\n",
      "917657750000.0\n",
      "877167600.0\n",
      "400191550000.0\n",
      "1079174900000.0\n",
      "48890820000.0\n",
      "998668700000.0\n",
      "597571900000.0\n",
      "249035030000.0\n",
      "668130400000.0\n",
      "482024420000.0\n",
      "16306045000.0\n",
      "-21030267000.0\n",
      "457414280000.0\n",
      "107710210000.0\n",
      "-171063180000.0\n",
      "327928800000.0\n",
      "1862428700000.0\n",
      "-76635600000.0\n",
      "527725630000.0\n",
      "525290000000.0\n",
      "381338940000.0\n",
      "1398724800000.0\n",
      "836418000000.0\n",
      "99992084000.0\n",
      "903843900000.0\n",
      "8732436000.0\n",
      "431212660000.0\n",
      "-14920013000.0\n",
      "223969280.0\n",
      "42134106000.0\n",
      "-2091543600.0\n",
      "521133620000.0\n",
      "33877290000.0\n",
      "492385400000.0\n",
      "479395000000.0\n",
      "58882064000.0\n",
      "669773800000.0\n",
      "24566882000.0\n",
      "1420136000.0\n",
      "240659050000.0\n",
      "1673650600000.0\n",
      "87597646000.0\n",
      "8993549000.0\n",
      "212344640000.0\n",
      "34775750000.0\n",
      "28831195000.0\n",
      "-15436148000.0\n",
      "3584793600.0\n",
      "-31988220000.0\n",
      "3634047000000.0\n",
      "26184937000.0\n",
      "-14305987000.0\n",
      "7426820000.0\n",
      "377940280000.0\n",
      "1344954000000.0\n",
      "122262980000.0\n",
      "21933998000.0\n",
      "1319958600000.0\n",
      "323566500000.0\n",
      "487797700000.0\n",
      "1381226500000.0\n",
      "-37289010000.0\n",
      "11225360000.0\n",
      "180646670000.0\n",
      "361060000000.0\n",
      "106963030000.0\n",
      "745896800000.0\n",
      "1415892000000.0\n",
      "266641850000.0\n",
      "2527061900000.0\n",
      "108016026000.0\n",
      "351934450000.0\n",
      "64373514000.0\n",
      "1818564600000.0\n",
      "525835930000.0\n",
      "1153916200000.0\n",
      "5823333400.0\n",
      "814753300000.0\n",
      "33385337000.0\n",
      "572240170000.0\n",
      "675388060000.0\n",
      "11127011000.0\n",
      "3270944800000.0\n",
      "-14363534000.0\n",
      "76746570000.0\n",
      "22353970000.0\n",
      "551281360000.0\n",
      "-10115606000.0\n",
      "-33903080000.0\n",
      "562429760000.0\n",
      "201536030000.0\n",
      "1543180500000.0\n",
      "34517040000.0\n",
      "508998520000.0\n",
      "115791050000.0\n",
      "124756990000.0\n",
      "53578110000.0\n",
      "135810500000.0\n",
      "101674560000.0\n",
      "-757225500.0\n",
      "107560700000.0\n",
      "150571020000.0\n",
      "2701354000.0\n",
      "224639530000.0\n",
      "111823610000.0\n",
      "21117755000.0\n",
      "972174500000.0\n",
      "290355800000.0\n",
      "17093544000.0\n",
      "416797720000.0\n",
      "36470645000.0\n",
      "110303930000.0\n",
      "921032700.0\n",
      "27683607000.0\n",
      "431396200000.0\n",
      "1027797350000.0\n",
      "345900060000.0\n",
      "-10322342000.0\n",
      "668264370000.0\n",
      "-53709390000.0\n",
      "346617970000.0\n",
      "1487462400.0\n",
      "96458640000.0\n",
      "121122710000.0\n",
      "30677283000.0\n",
      "175029080000.0\n",
      "2757723100.0\n",
      "54073815000.0\n",
      "161784330000.0\n",
      "76118606000.0\n",
      "204381520000.0\n",
      "220403730000.0\n",
      "65253360000.0\n",
      "152201690000.0\n",
      "-28157354000.0\n",
      "6508039700.0\n",
      "341746680000.0\n",
      "114949956000.0\n",
      "1218193400000.0\n",
      "96064110000.0\n",
      "53658354000.0\n",
      "-28346702000.0\n",
      "-11011801000.0\n",
      "37630693000.0\n",
      "84793100000.0\n",
      "52847817000.0\n",
      "27474842000.0\n",
      "24117248000.0\n",
      "-109138450000.0\n",
      "-40576120000.0\n",
      "2186152200000.0\n",
      "50751140000.0\n",
      "164614930000.0\n",
      "80649765000.0\n",
      "208807540000.0\n",
      "274633540000.0\n",
      "76608570000.0\n",
      "1233128400000.0\n",
      "292376250000.0\n",
      "1209303200000.0\n",
      "213620670000.0\n",
      "828879300000.0\n",
      "417345080000.0\n",
      "37389730000.0\n",
      "218230440000.0\n",
      "128060000000.0\n",
      "4497082000000.0\n",
      "-48345887000.0\n",
      "291349700000.0\n",
      "432847600000.0\n",
      "506663930000.0\n",
      "1471051500000.0\n",
      "-98538800000.0\n",
      "377264770000.0\n",
      "-33977926000.0\n",
      "29551852000.0\n",
      "323727000000.0\n",
      "134828180000.0\n",
      "338367480000.0\n",
      "104072200000.0\n",
      "58157515000.0\n",
      "4197034000.0\n",
      "782893000000.0\n",
      "189407040000.0\n",
      "848564060000.0\n",
      "1263818600000.0\n",
      "237349730000.0\n",
      "8479031300.0\n",
      "177225290000.0\n",
      "439580850000.0\n",
      "11921654000.0\n",
      "219287550000.0\n",
      "3873051600.0\n",
      "9589316000.0\n",
      "507503600000.0\n",
      "2421530800000.0\n",
      "-4663944000.0\n",
      "3679251500.0\n",
      "1006014200000.0\n",
      "221225480000.0\n",
      "1106863300000.0\n",
      "149421850000.0\n",
      "5400531000.0\n",
      "30330063000.0\n",
      "-5560418300.0\n",
      "1776051600000.0\n",
      "1536823100000.0\n",
      "414913100000.0\n",
      "26205585000.0\n",
      "43297616000.0\n",
      "1077353000000.0\n",
      "16888633000.0\n",
      "306023100000.0\n",
      "296394720000.0\n",
      "133546130000.0\n",
      "58793034000.0\n",
      "4832547600000.0\n",
      "9707918000.0\n",
      "122676200000.0\n",
      "264634560000.0\n",
      "277928570000.0\n",
      "39714845000.0\n",
      "3220190200.0\n",
      "32930080000.0\n",
      "-66057306000.0\n",
      "-20229915000.0\n",
      "1072913060000.0\n",
      "-22581600000.0\n",
      "-7112900600.0\n",
      "16051778000.0\n",
      "106175150000.0\n",
      "357139250000.0\n",
      "871372160000.0\n",
      "11860748000.0\n",
      "433272980000.0\n",
      "66104410000.0\n",
      "158282740000.0\n",
      "1476146800000.0\n",
      "87041800000.0\n",
      "281551200000.0\n",
      "1105246600000.0\n",
      "116155450000.0\n",
      "88937060000.0\n",
      "7657268000.0\n",
      "-9689618000.0\n",
      "-17895252000.0\n",
      "4460329000.0\n",
      "-40841160000.0\n",
      "-22299912000.0\n",
      "526737700000.0\n",
      "441123300000.0\n",
      "286386620000.0\n",
      "542327700000.0\n",
      "1466419500000.0\n",
      "522658840000.0\n",
      "133201820000.0\n",
      "-18510053000.0\n",
      "-34686358000.0\n",
      "-13314605000.0\n",
      "243176050000.0\n",
      "2093238300000.0\n",
      "62252073000.0\n",
      "147901990000.0\n",
      "-20493427000.0\n",
      "881851100000.0\n",
      "9280141000.0\n",
      "282658640000.0\n",
      "18218189000.0\n",
      "2091203300000.0\n",
      "11138153000.0\n",
      "3055753400000.0\n",
      "33340035000.0\n",
      "316260550000.0\n",
      "-86577420000.0\n",
      "28729147000.0\n",
      "9541837000.0\n",
      "133112650000.0\n",
      "149276490000.0\n",
      "577551000000.0\n",
      "79162670000.0\n",
      "278575640000.0\n",
      "-7901815300.0\n",
      "27926544000.0\n",
      "79302885000.0\n",
      "-9363527000.0\n",
      "212375860000.0\n",
      "49430630000.0\n",
      "1834751800000.0\n",
      "327740950000.0\n",
      "42160580000.0\n",
      "111831700000.0\n",
      "1057031100000.0\n",
      "18144182000.0\n",
      "-58523963000.0\n",
      "-26082296000.0\n",
      "241012150000.0\n",
      "404801780000.0\n",
      "19794688000.0\n",
      "399397160000.0\n",
      "-6175505400.0\n",
      "-26601775000.0\n",
      "328537830000.0\n",
      "40828506000.0\n",
      "166172970000.0\n",
      "48020310000.0\n",
      "35080524000.0\n",
      "974127100.0\n",
      "137630520000.0\n",
      "636109600000.0\n",
      "84261800000.0\n",
      "236637110000.0\n",
      "14077829000.0\n",
      "-32959943000.0\n",
      "24350876000.0\n",
      "314170250000.0\n",
      "362340450000.0\n",
      "-231662750000.0\n",
      "171962780000.0\n",
      "357379470000.0\n",
      "409130340000.0\n",
      "172172720000.0\n",
      "286671300000.0\n",
      "3053919400000.0\n",
      "74258145000.0\n",
      "-187394050.0\n",
      "137172500000.0\n",
      "53480006000.0\n",
      "10392756000.0\n",
      "212171130000.0\n",
      "200997370000.0\n",
      "449003060000.0\n",
      "244683400000.0\n",
      "1386471400.0\n",
      "1655965200000.0\n",
      "56424730000.0\n",
      "5866860500.0\n",
      "782395700000.0\n",
      "-16291262000.0\n",
      "152506060000.0\n",
      "552148530000.0\n",
      "-17389933000.0\n",
      "-8502591500.0\n",
      "2037907200000.0\n",
      "53679910000.0\n",
      "452039670000.0\n",
      "-34011216000.0\n",
      "140932120000.0\n",
      "17632874000.0\n",
      "16432543000.0\n",
      "356492400000.0\n",
      "861790700000.0\n",
      "1046172200000.0\n",
      "29584933000.0\n",
      "801714860000.0\n",
      "690869100000.0\n",
      "-4726692000.0\n",
      "202005970000.0\n",
      "322640900.0\n",
      "51369420000.0\n",
      "-4225900000.0\n",
      "1419655000000.0\n",
      "47768257000.0\n",
      "132476990000.0\n",
      "175762950000.0\n",
      "870898500000.0\n",
      "-3954007000.0\n",
      "286215570000.0\n",
      "-24960094000.0\n",
      "169681980000.0\n",
      "46261977000.0\n",
      "340181120000.0\n",
      "604039800000.0\n",
      "-18505888000.0\n",
      "776903660000.0\n",
      "6541519000000.0\n",
      "49859166000.0\n",
      "753175040000.0\n",
      "-30659654000.0\n",
      "1570920000000.0\n",
      "-6766343000.0\n",
      "178386200000.0\n",
      "19637182000.0\n",
      "163464230000.0\n",
      "25588154000.0\n",
      "-159199300000.0\n",
      "1536581200000.0\n",
      "-17135010000.0\n",
      "35831060000.0\n",
      "-33674170000.0\n",
      "224582090000.0\n",
      "316496120000.0\n",
      "16185258000.0\n",
      "421175700000.0\n",
      "43511980000.0\n",
      "-21995393000.0\n",
      "2540928200000.0\n",
      "314680500000.0\n",
      "106483520000.0\n",
      "953160200000.0\n",
      "1223086000000.0\n",
      "393455900000.0\n",
      "-24975262000.0\n",
      "-69543980000.0\n",
      "37036823000.0\n",
      "315480570000.0\n",
      "404323800000.0\n",
      "53732266000.0\n",
      "1112983000000.0\n",
      "945524200000.0\n",
      "54562996000.0\n",
      "-6671516700.0\n",
      "498018320000.0\n",
      "476457140000.0\n",
      "-7682060300.0\n",
      "31033727000.0\n",
      "1792932700000.0\n",
      "2893638800000.0\n",
      "2421018900000.0\n",
      "385361050000.0\n",
      "301770180000.0\n",
      "-23503565000.0\n",
      "42085130000.0\n",
      "6152997000.0\n",
      "17594310000.0\n",
      "-66658853000.0\n",
      "-28264090000.0\n",
      "796571600000.0\n",
      "142264190000.0\n",
      "-18211772000.0\n",
      "101042330000.0\n",
      "43574706000.0\n",
      "371668420000.0\n",
      "-21287875000.0\n",
      "370155750000.0\n",
      "-9225700000.0\n",
      "64547676000.0\n",
      "89522550000.0\n",
      "263764660000.0\n",
      "-24881543000.0\n",
      "897572900000.0\n",
      "2084690600000.0\n",
      "-38683740000.0\n",
      "17445659000.0\n",
      "392420620000.0\n",
      "407542560000.0\n",
      "2179188000000.0\n",
      "121705810000.0\n",
      "32569848000.0\n",
      "3098846000000.0\n",
      "651164100000.0\n",
      "-37689810000.0\n",
      "23226888000.0\n",
      "-5291333600.0\n",
      "916876700000.0\n",
      "-5465465000.0\n",
      "314276800000.0\n",
      "1701004200000.0\n",
      "894030840000.0\n",
      "400814370000.0\n",
      "66010202000.0\n",
      "999908050000.0\n",
      "17134584000.0\n",
      "261194550000.0\n",
      "174475870000.0\n",
      "8273805300.0\n",
      "222532260000.0\n",
      "44877410000.0\n",
      "922268140000.0\n",
      "133777920000.0\n",
      "26650288000.0\n",
      "67993895000.0\n",
      "-648277000.0\n",
      "479838700000.0\n",
      "34515042000.0\n",
      "186353190000.0\n",
      "51733545000.0\n",
      "44686810000.0\n",
      "550704800000.0\n",
      "386275050000.0\n",
      "422464780000.0\n",
      "1042013200.0\n",
      "77147010000.0\n",
      "-16055598000.0\n",
      "706986100000.0\n",
      "71107000000.0\n",
      "33982462000.0\n",
      "348574500000.0\n",
      "576274240000.0\n",
      "10638511000.0\n",
      "416956100000.0\n",
      "389472850000.0\n",
      "-57899053000.0\n",
      "40063560000.0\n",
      "42318234000.0\n",
      "413752000000.0\n",
      "59109933000.0\n",
      "-8434436600.0\n",
      "-17456826000.0\n",
      "-26203281000.0\n",
      "432009350000.0\n",
      "-19557466000.0\n",
      "-30312092000.0\n",
      "26083957000.0\n",
      "8497092600.0\n",
      "7740868600.0\n",
      "5369642000.0\n",
      "366262030000.0\n",
      "-24681550000.0\n",
      "176751740000.0\n",
      "-128233230000.0\n",
      "221886500000.0\n",
      "267297730000.0\n",
      "-121866240.0\n",
      "381845400000.0\n",
      "-11464728000.0\n",
      "9214370000.0\n",
      "166834400000.0\n",
      "800577600000.0\n",
      "40376017000.0\n",
      "99596320000.0\n",
      "61972464000.0\n",
      "125116680000.0\n",
      "5233776600.0\n",
      "44324282000.0\n",
      "1012047740000.0\n",
      "300619700000.0\n",
      "453851100000.0\n",
      "-6537939500.0\n",
      "443296000000.0\n",
      "235071930000.0\n",
      "28419645000.0\n",
      "6720535600.0\n",
      "3273679400000.0\n",
      "-3764604000.0\n",
      "865602960000.0\n",
      "485050000000.0\n",
      "135624980000.0\n",
      "60081470000.0\n",
      "423904020000.0\n",
      "508285550000.0\n",
      "103031800000.0\n",
      "-41208570000.0\n",
      "147534100000.0\n",
      "286045540000.0\n",
      "-33784097000.0\n",
      "28134461000.0\n",
      "257688470000.0\n",
      "140773490000.0\n",
      "345896420000.0\n",
      "-12890317000.0\n"
     ]
    }
   ],
   "source": [
    "lista1 = []\n",
    "for item in pred2:\n",
    "    print(max(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 3, 1, 1, 3, 3, 3, 1, 3, 0, 3, 1, 0, 7, 3, 0, 1, 3, 0, 6, 0, 1, 3, 3, 0, 3, 1, 7, 0, 6, 3, 2, 1, 3, 3, 3, 1, 6, 0, 3, 1, 1, 3, 3, 0, 3, 3, 0, 1, 3, 3, 3, 3, 2, 6, 1, 0, 0, 6, 0, 1, 6, 0, 0, 7, 1, 3, 1, 1, 3, 0, 3, 1, 3, 3, 3, 0, 3, 0, 3, 0, 0, 1, 0, 1, 3, 0, 1, 3, 1, 2, 0, 3, 7, 1, 3, 1, 1, 3, 3, 0, 0, 2, 0, 2, 0, 3, 1, 3, 3, 3, 1, 0, 7, 0, 3, 3, 3, 3, 0, 0, 1, 3, 3, 3, 0, 0, 0, 0, 0, 3, 0, 0, 1, 3, 1, 0, 1, 5, 7, 1, 3, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 3, 3, 1, 3, 1, 0, 3, 2, 3, 0, 1, 3, 7, 1, 3, 6, 1, 3, 1, 3, 1, 0, 3, 3, 3, 0, 0, 0, 1, 3, 1, 3, 3, 1, 0, 0, 0, 0, 3, 0, 3, 1, 7, 2, 6, 1, 3, 3, 1, 0, 3, 0, 0, 3, 7, 1, 3, 3, 0, 3, 0, 0, 1, 3, 0, 0, 3, 0, 0, 0, 0, 1, 3, 3, 2, 1, 1, 3, 1, 2, 0, 0, 1, 1, 1, 1, 0, 3, 1, 6, 6, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 3, 1, 0, 0, 3, 0, 1, 0, 3, 0, 0, 1, 3, 0, 3, 3, 0, 0, 3, 0, 1, 1, 3, 0, 1, 3, 3, 6, 0, 0, 0, 5, 3, 0, 3, 3, 3, 1, 1, 0, 1, 2, 1, 0, 3, 1, 3, 1, 3, 3, 3, 0, 1, 0, 0, 1, 0, 0, 6, 3, 1, 1, 1, 0, 3, 3, 0, 3, 0, 3, 3, 5, 1, 6, 1, 0, 7, 0, 3, 3, 0, 0, 2, 3, 0, 0, 1, 3, 1, 0, 3, 1, 3, 1, 3, 1, 3, 1, 1, 3, 3, 3, 3, 0, 1, 1, 3, 0, 3, 1, 1, 0, 1, 3, 0, 1, 0, 0, 1, 3, 3, 0, 3, 1, 2, 3, 3, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 3, 0, 1, 0, 2, 1, 3, 1, 1, 3, 0, 3, 6, 3, 1, 1, 3, 3, 1, 1, 0, 0, 0, 3, 1, 3, 0, 0, 3, 1, 3, 3, 3, 3, 0, 0, 1, 3, 0, 3, 1, 0, 3, 0, 3, 1, 3, 1, 3, 0, 3, 0, 6, 0, 0, 3, 0, 0, 0, 3, 2, 3, 3, 3, 0, 1, 1, 0, 3, 1, 1, 3, 3, 1, 1, 1, 3, 0, 3, 3, 0, 2, 0, 0, 0, 3, 0, 0, 3, 3, 1, 2, 0, 0, 1, 0, 1, 1, 2, 3, 0, 0, 1, 0, 3, 3, 1, 3, 7, 0, 3, 1, 3, 3, 7, 3, 1, 0, 1, 1, 0, 1, 3, 0, 0, 0, 3, 6, 3, 1, 1, 1, 0, 3, 0, 0, 1, 3, 1, 0, 3, 3, 1, 3, 3, 3, 1, 0, 3, 0, 0, 0, 2, 0, 1, 0, 7, 1, 0, 0, 3, 7, 1, 0, 3, 0, 1, 1, 0, 7, 1, 3, 1, 0, 5, 3, 0, 0, 0, 6, 2, 1, 3, 3, 3, 0, 1, 3, 3, 2, 3, 3, 3, 0, 1, 3, 6, 1, 3, 3, 5, 3, 0, 3, 2, 1, 3, 3, 1, 3, 1, 3, 0, 1, 3, 3, 1, 3, 1, 7, 0, 3, 3, 0, 3, 0, 0, 3, 1, 0, 0, 1, 1, 3, 3, 3, 1, 3, 1, 0, 1, 3, 1, 3, 3, 1, 3, 3, 0, 3, 1, 3, 1, 0, 1, 3, 1, 0, 3, 1, 3, 1, 0, 3, 1, 0, 0, 1, 3, 0, 3, 3, 3, 0, 1, 2, 1, 3, 0, 5, 3, 3, 0, 1, 0, 1, 3, 1, 3, 3, 3, 3, 0, 1, 3, 3, 6, 1, 5, 3, 3, 1, 0, 3, 3, 1, 0, 1, 3, 0, 1, 1, 3, 3, 6, 1, 3, 0, 3, 3, 1, 3, 2, 0, 0, 1, 3, 1, 0, 3, 0, 0, 3, 3, 1, 0, 0, 1, 0, 3, 3, 0, 3, 0, 1, 0, 2, 0, 3, 1, 3, 0, 3, 1, 7, 1, 0, 0, 3, 0, 3, 1, 0, 3, 0, 3, 3, 0, 6, 1, 3, 1, 0, 1, 1, 1, 1, 1, 1, 6, 1, 0, 0, 6, 3, 1, 3, 1, 2, 0, 3, 0, 6, 3, 3, 1, 6, 3, 0, 0, 1, 3, 0, 1, 1, 3, 1, 0, 3, 2, 0, 3, 0, 3, 2, 3, 6, 1, 1, 0, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "lista = []\n",
    "for item in pred2:\n",
    "    lista.append(list(item).index(max(item)))\n",
    "print(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 0, 3, 1, 1, 3, 3, 3, 1, 3, 1, 3, 2, 0, 5, 3, 0, 1, 3, 0, 5, 0, 2, 3, 3, 0, 3, 0, 6, 0, 6, 7, 2, 1, 3, 7, 3, 1, 7, 0, 3, 1, 7, 1, 3, 0, 3, 3, 1, 3, 3, 3, 3, 3, 7, 5, 1, 0, 0, 5, 0, 1, 2, 1, 0, 7, 1, 3, 1, 1, 3, 1, 1, 1, 3, 3, 3, 0, 3, 0, 3, 0, 0, 6, 0, 3, 3, 4, 0, 1, 0, 3, 0, 2, 7, 1, 3, 0, 2, 3, 3, 1, 0, 1, 0, 2, 0, 3, 1, 3, 3, 3, 5, 0, 3, 2, 3, 3, 7, 3, 0, 0, 5, 3, 3, 3, 3, 1, 0, 0, 0, 3, 0, 0, 1, 3, 1, 0, 3, 5, 2, 1, 7, 3, 0, 4, 0, 4, 0, 1, 0, 1, 1, 1, 1, 3, 3, 0, 0, 3, 7, 5, 3, 7, 1, 2, 7, 3, 0, 0, 3, 6, 1, 1, 3, 1, 3, 1, 3, 1, 3, 6, 3, 3, 1, 0, 2, 1, 3, 1, 3, 7, 1, 0, 0, 0, 5, 3, 0, 1, 1, 3, 1, 6, 1, 3, 1, 7, 0, 3, 0, 0, 3, 7, 1, 1, 3, 0, 3, 0, 0, 3, 6, 0, 0, 3, 2, 1, 2, 0, 1, 3, 2, 6, 1, 1, 1, 1, 3, 0, 0, 1, 1, 1, 1, 1, 3, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 2, 0, 0, 3, 3, 0, 1, 2, 3, 0, 1, 0, 3, 0, 0, 2, 1, 0, 3, 3, 0, 0, 3, 3, 2, 1, 3, 3, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3, 1, 3, 1, 1, 1, 2, 5, 1, 0, 3, 4, 3, 2, 3, 3, 3, 0, 1, 0, 0, 2, 0, 0, 1, 3, 1, 1, 1, 2, 3, 7, 1, 3, 0, 3, 3, 6, 1, 6, 5, 1, 7, 0, 3, 3, 0, 0, 3, 3, 0, 0, 1, 3, 2, 0, 3, 1, 3, 1, 3, 1, 3, 1, 1, 3, 3, 3, 3, 0, 3, 1, 3, 0, 3, 1, 1, 2, 1, 1, 1, 2, 3, 0, 1, 3, 3, 0, 0, 1, 1, 3, 3, 1, 0, 1, 0, 1, 0, 0, 0, 2, 1, 3, 0, 1, 0, 7, 3, 3, 1, 1, 3, 0, 3, 1, 5, 1, 3, 1, 3, 2, 1, 0, 4, 0, 3, 1, 3, 0, 0, 3, 5, 3, 1, 3, 3, 0, 0, 1, 3, 0, 3, 1, 4, 3, 0, 1, 1, 3, 1, 1, 0, 3, 0, 6, 3, 1, 3, 0, 0, 0, 3, 5, 3, 3, 3, 0, 3, 3, 0, 3, 1, 1, 3, 3, 3, 3, 1, 3, 1, 3, 3, 0, 2, 0, 0, 0, 3, 3, 1, 6, 3, 5, 2, 0, 0, 1, 1, 1, 1, 6, 3, 2, 0, 1, 0, 3, 3, 1, 3, 7, 0, 3, 5, 3, 3, 7, 3, 1, 0, 5, 1, 0, 1, 3, 0, 0, 5, 3, 6, 3, 1, 1, 2, 3, 3, 1, 0, 1, 3, 1, 0, 3, 3, 1, 3, 3, 3, 1, 1, 3, 6, 0, 0, 1, 0, 1, 2, 1, 1, 0, 3, 3, 5, 3, 1, 3, 0, 6, 1, 0, 7, 1, 3, 1, 0, 3, 3, 0, 0, 0, 7, 2, 1, 3, 3, 3, 0, 1, 3, 7, 1, 3, 3, 3, 0, 0, 3, 5, 1, 3, 3, 4, 3, 0, 3, 5, 1, 3, 3, 5, 3, 1, 3, 0, 1, 1, 3, 2, 3, 1, 6, 0, 2, 3, 0, 3, 0, 0, 3, 2, 0, 0, 1, 1, 3, 3, 3, 3, 3, 1, 0, 1, 3, 1, 3, 3, 1, 3, 3, 0, 3, 1, 3, 2, 0, 6, 3, 1, 1, 3, 1, 3, 5, 0, 3, 1, 0, 0, 1, 3, 0, 3, 3, 3, 0, 1, 1, 2, 3, 0, 2, 3, 3, 0, 1, 0, 3, 5, 1, 3, 3, 3, 3, 3, 1, 3, 3, 5, 1, 2, 3, 3, 1, 0, 3, 3, 1, 0, 1, 7, 0, 2, 3, 3, 3, 6, 1, 3, 0, 3, 3, 1, 3, 5, 2, 0, 1, 3, 1, 0, 3, 3, 0, 1, 3, 1, 0, 0, 1, 0, 1, 3, 0, 1, 0, 2, 0, 7, 1, 3, 1, 3, 0, 3, 1, 6, 1, 0, 0, 1, 0, 6, 1, 0, 3, 2, 3, 3, 0, 1, 2, 1, 1, 0, 1, 5, 6, 1, 1, 1, 6, 1, 1, 1, 7, 3, 1, 3, 1, 1, 3, 3, 0, 1, 3, 3, 1, 6, 3, 0, 0, 1, 3, 0, 3, 5, 3, 1, 0, 3, 1, 0, 3, 0, 5, 5, 3, 6, 2, 1, 0, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "#path= '/home/israagus/Escritorio/ReEntrenamientos/Entrenamiento1/CT30mP_picudo'\n",
    "#data1=np.array(pickle.load(open(path+\".pickle\",\"rb\"))) #np.load()\n",
    "l = []\n",
    "for i in range(824):\n",
    "    l.append(data1[i][1].index(1))\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [824, 0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-e52d454187f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlista\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmatriz_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatriz_conf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \"\"\"\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [824, 0]"
     ]
    }
   ],
   "source": [
    "y_test = lista\n",
    "y_pred = l\n",
    "matriz_conf = confusion_matrix(y_true = y_test,y_pred=y_pred)\n",
    "print(matriz_conf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
